{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "\n",
    "TRAIN_FEATURES = os.path.join(DATA_PATH, 'train_text_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_FEATURES, index_col=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization and stop words elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "\n",
    "def text_lem_stopwords(df=train_df, col='text_cleaned'):\n",
    "    df['preprocessed_text'] = (\n",
    "        df[col].apply(lambda x:\n",
    "                      ' '.join([w.lemma_ for w in list(nlp(x)) if (w.is_stop == False)]))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake may allah forgive us all</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected</td>\n",
       "      <td>resident ask shelter place notify officer evacuation shelter place order expect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in california</td>\n",
       "      <td>people receive wildfire evacuation order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as smoke from wildfires pours into a school</td>\n",
       "      <td>get send photo ruby alaska smoke wildfire pour school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant cranes holding a bridge collapse into nearby homes</td>\n",
       "      <td>giant crane hold bridge collapse nearby home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
       "      <td>1</td>\n",
       "      <td>the out of control wild fires in california even in the northern part of the state very troubling</td>\n",
       "      <td>control wild fire california northern state troubling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7517</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
       "      <td>1</td>\n",
       "      <td>m utc km s of volcano hawaii</td>\n",
       "      <td>m utc km s volcano hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
       "      <td>1</td>\n",
       "      <td>police investigating after an e bike collided with a car in little portugal e bike rider suffered serious non life threatening injuries</td>\n",
       "      <td>police investigate e bike collide car little portugal e bike rider suffer non life threaten injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
       "      <td>1</td>\n",
       "      <td>the latest more homes razed by northern california wildfire abc news</td>\n",
       "      <td>late home raze northern california wildfire abc news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7520 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text  target                                                                                                                             text_cleaned                                                                                   preprocessed_text\n",
       "0                                                                         Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all       1                                                                     our deeds are the reason of this earthquake may allah forgive us all                                                                deed reason earthquake allah forgive\n",
       "1                                                                                                        Forest fire near La Ronge Sask. Canada       1                                                                                                    forest fire near la ronge sask canada                                                               forest fire near la ronge sask canada\n",
       "2         All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected       1       all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected                     resident ask shelter place notify officer evacuation shelter place order expect\n",
       "3                                                                             13,000 people receive #wildfires evacuation orders in California        1                                                                                 people receive wildfires evacuation orders in california                                                 people receive wildfire evacuation order california\n",
       "4                                                      Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school        1                                                    just got sent this photo from ruby alaska as smoke from wildfires pours into a school                                               get send photo ruby alaska smoke wildfire pour school\n",
       "...                                                                                                                                         ...     ...                                                                                                                                      ...                                                                                                 ...\n",
       "7515                                                        Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5       1                                                                             two giant cranes holding a bridge collapse into nearby homes                                                        giant crane hold bridge collapse nearby home\n",
       "7516              @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.       1                                        the out of control wild fires in california even in the northern part of the state very troubling                                               control wild fire california northern state troubling\n",
       "7517                                                                          M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ       1                                                                                                             m utc km s of volcano hawaii                                                                           m utc km s volcano hawaii\n",
       "7518  Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.       1  police investigating after an e bike collided with a car in little portugal e bike rider suffered serious non life threatening injuries  police investigate e bike collide car little portugal e bike rider suffer non life threaten injury\n",
       "7519                                             The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d       1                                                                     the latest more homes razed by northern california wildfire abc news                                                late home raze northern california wildfire abc news\n",
       "\n",
       "[7520 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = text_lem_stopwords(df=train_df, col='text_cleaned')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    " - sentence_count - total number of sentences\n",
    " - word_count - number of words in text\n",
    " - unique_word_count - number of unique words in text\n",
    " - unique_word_share - ratio between number of unique words and number of total words\n",
    " - stop_word_count - number of stop words in text\n",
    " - stop_word_share - ratio between number of stopwords and number of total words\n",
    " - url_count - number of urls in text\n",
    " - mean_word_length - average word length count in text\n",
    " - char_count - number of characters in text\n",
    " - punctuation_count - number of punctuations in text\n",
    " - hashtag_count - number of hashtags (#) in text\n",
    " - mention_count - number of mentions (@) in text\n",
    "\n",
    " - polarity_raw, polarity_preprocessed - polarity in raw and preprocessed text respectively using textblob\n",
    " - subjectivity_raw, subjectivity_preprocessed - subjectivity in raw and preprocessed text respectively using textblob\n",
    " - tags_count - “tagging” parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_count(tweet_df, col='text'):\n",
    "    tweet_df['sentence_count'] = tweet_df[col].apply(lambda x: x.count('\\n') + 1)\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(tweet_df, col='text'):\n",
    "    tweet_df['word_count'] = tweet_df[col].apply(lambda x: len(str(x).split()))\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_word_count(tweet_df, col='text'):\n",
    "    tweet_df['unique_word_count'] = (\n",
    "            tweet_df[col].apply(lambda x: len(set(str(x).split())))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_word_share(tweet_df, col='text'):\n",
    "    tweet_df['unique_word_share'] = (\n",
    "            tweet_df[col].apply(lambda x: len(set(x.split())) / len(x.split()) \n",
    "                                if len(x.split())!=0 else 0)\n",
    "    )\n",
    "    \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stop_word_count(tweet_df, col='text'):\n",
    "    tweet_df['stop_word_count'] = (\n",
    "        tweet_df[col]\n",
    "            .apply(lambda x:\n",
    "                   len([w for w in str(x).lower().split()\n",
    "                        if w in stop_words]))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_share(tweet_df, col='text'):\n",
    "    tweet_df['stop_word_share'] = (\n",
    "            tweet_df[col].apply(lambda x:\n",
    "                                len([w for w in str(x).lower().split()\n",
    "                                     if w in stop_words]) / len(x.split())\n",
    "                               if len(x.split())!=0 else 0)\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_count(tweet_df, col='text'):\n",
    "    tweet_df['url_count'] = (\n",
    "                tweet_df[col]\n",
    "                    .apply(lambda x: \n",
    "                           len([w for w in str(x).lower().split() \n",
    "                            if 'http' in w or 'https' in w]))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_word_length(tweet_df, col='text'):\n",
    "    tweet_df['mean_word_length'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(tweet_df, col='text'):\n",
    "    tweet_df['char_count'] = (\n",
    "            tweet_df[col].apply(lambda x: len(str(x)))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_count(tweet_df, col='text'):\n",
    "    tweet_df['punctuation_count'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_count(tweet_df, col='text'):\n",
    "    tweet_df['hashtag_count'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: len([c for c in str(x) if c == '#']))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention_count(tweet_df, col='text'):\n",
    "    tweet_df['mention_count'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: len([c for c in str(x) if c == '@']))\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_raw(tweet_df, col='text'):\n",
    "    tweet_df['polarity_raw'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: TextBlob(x).sentiment[0])\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(tweet_df, col='text'):\n",
    "    tweet_df['polarity'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: TextBlob(x).sentiment[0])\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_raw(tweet_df, col='text'):\n",
    "    tweet_df['subjectivity_raw'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: TextBlob(x).sentiment[1])\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(tweet_df, col='text'):\n",
    "    tweet_df['subjectivity'] = (\n",
    "            tweet_df[col].apply(\n",
    "                lambda x: TextBlob(x).sentiment[1])\n",
    "    )\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_feature_engineering_cleaned(tweet_df, tweet_col='text'):\n",
    "    tweet_new_features = tweet_df.copy()\n",
    "    tweet_new_features = sentence_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = word_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = stop_word_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = stop_word_share(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = url_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = mean_word_length(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = char_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = punctuation_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = hashtag_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = mention_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = polarity_raw(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = subjectivity_raw(tweet_new_features, col=tweet_col)\n",
    "    \n",
    "    return tweet_new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_feature_engineering_preprocessed(tweet_df, tweet_col='preprocessed_text'):\n",
    "    tweet_new_features = tweet_df.copy()\n",
    "    tweet_new_features = unique_word_count(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = unique_word_share(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = polarity(tweet_new_features, col=tweet_col)\n",
    "    tweet_new_features = subjectivity(tweet_new_features, col=tweet_col)\n",
    "    \n",
    "    return tweet_new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_count(tweet_df, tweet_col='text_cleaned'):\n",
    "    tweet_new_features = tweet_df.copy()\n",
    "    text_tag = tweet_new_features[tweet_col].apply(lambda x: TextBlob(x).tags)\n",
    "    tagList = [Counter(pair[1] for pair in row).most_common() for row in text_tag]\n",
    "    for index, row_tag in enumerate(tagList):\n",
    "        for key, value in row_tag:\n",
    "            tweet_new_features.loc[index,key] = value\n",
    "\n",
    "    tweet_new_features.fillna(0, inplace = True)\n",
    "    \n",
    "    return tweet_new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_new = tweet_feature_engineering_cleaned(train_df, tweet_col='text')\n",
    "train_df_new = tweet_feature_engineering_preprocessed(train_df_new, tweet_col='preprocessed_text')\n",
    "train_df_new = tags_count(train_df_new, tweet_col='text_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>stop_word_share</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>polarity_raw</th>\n",
       "      <th>subjectivity_raw</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>unique_word_share</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>PRP$</th>\n",
       "      <th>NNS</th>\n",
       "      <th>VBP</th>\n",
       "      <th>IN</th>\n",
       "      <th>MD</th>\n",
       "      <th>VB</th>\n",
       "      <th>JJ</th>\n",
       "      <th>PRP</th>\n",
       "      <th>JJS</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBD</th>\n",
       "      <th>TO</th>\n",
       "      <th>VBG</th>\n",
       "      <th>CC</th>\n",
       "      <th>RB</th>\n",
       "      <th>EX</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>CD</th>\n",
       "      <th>WP</th>\n",
       "      <th>RP</th>\n",
       "      <th>JJR</th>\n",
       "      <th>WRB</th>\n",
       "      <th>FW</th>\n",
       "      <th>WDT</th>\n",
       "      <th>NNP</th>\n",
       "      <th>RBR</th>\n",
       "      <th>RBS</th>\n",
       "      <th>PDT</th>\n",
       "      <th>SYM</th>\n",
       "      <th>UH</th>\n",
       "      <th>WP$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake may allah forgive us all</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected</td>\n",
       "      <td>resident ask shelter place notify officer evacuation shelter place order expect</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.01875</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>9</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in california</td>\n",
       "      <td>people receive wildfire evacuation order california</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as smoke from wildfires pours into a school</td>\n",
       "      <td>get send photo ruby alaska smoke wildfire pour school</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    text  target                                                                                                                        text_cleaned                                                                preprocessed_text  sentence_count  word_count  stop_word_count  stop_word_share  url_count  mean_word_length  char_count  punctuation_count  hashtag_count  mention_count  polarity_raw  subjectivity_raw  unique_word_count  unique_word_share  polarity  subjectivity   DT   NN  PRP$  NNS  VBP   IN   MD   VB   JJ  PRP  JJS  VBN  VBD   TO  VBG   CC   RB   EX  VBZ   CD   WP   RP  JJR  WRB   FW  WDT  NNP  RBR  RBS  PDT  SYM   UH  WP$\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all       1                                                                our deeds are the reason of this earthquake may allah forgive us all                                             deed reason earthquake allah forgive               1          13                6         0.461538          0          4.384615          69                  1              1              0       0.00000            0.0000                  5           1.000000       0.0           0.0  3.0  2.0   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada       1                                                                                               forest fire near la ronge sask canada                                            forest fire near la ronge sask canada               1           7                0         0.000000          0          4.571429          38                  1              0              0       0.10000            0.4000                  7           1.000000       0.1           0.4  0.0  4.0   0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected       1  all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected  resident ask shelter place notify officer evacuation shelter place order expect               1          22               11         0.500000          0          5.090909         133                  3              0              0      -0.01875            0.3875                  9           0.818182       0.0           0.0  2.0  4.0   0.0  3.0  2.0  3.0  0.0  1.0  1.0  0.0  0.0  2.0  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California        1                                                                            people receive wildfires evacuation orders in california                              people receive wildfire evacuation order california               1           8                1         0.125000          0          7.125000          65                  2              1              0       0.00000            0.0000                  6           1.000000       0.0           0.0  0.0  1.0   0.0  3.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school        1                                               just got sent this photo from ruby alaska as smoke from wildfires pours into a school                            get send photo ruby alaska smoke wildfire pour school               1          16                7         0.437500          0          4.500000          88                  2              2              0       0.00000            0.0000                  9           1.000000       0.0           0.0  2.0  4.0   0.0  1.0  1.0  4.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7520 entries, 0 to 7519\n",
      "Data columns (total 53 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   text               7520 non-null   object \n",
      " 1   target             7520 non-null   int64  \n",
      " 2   text_cleaned       7520 non-null   object \n",
      " 3   preprocessed_text  7520 non-null   object \n",
      " 4   sentence_count     7520 non-null   int64  \n",
      " 5   word_count         7520 non-null   int64  \n",
      " 6   stop_word_count    7520 non-null   int64  \n",
      " 7   stop_word_share    7520 non-null   float64\n",
      " 8   url_count          7520 non-null   int64  \n",
      " 9   mean_word_length   7520 non-null   float64\n",
      " 10  char_count         7520 non-null   int64  \n",
      " 11  punctuation_count  7520 non-null   int64  \n",
      " 12  hashtag_count      7520 non-null   int64  \n",
      " 13  mention_count      7520 non-null   int64  \n",
      " 14  polarity_raw       7520 non-null   float64\n",
      " 15  subjectivity_raw   7520 non-null   float64\n",
      " 16  unique_word_count  7520 non-null   int64  \n",
      " 17  unique_word_share  7520 non-null   float64\n",
      " 18  polarity           7520 non-null   float64\n",
      " 19  subjectivity       7520 non-null   float64\n",
      " 20  DT                 7520 non-null   float64\n",
      " 21  NN                 7520 non-null   float64\n",
      " 22  PRP$               7520 non-null   float64\n",
      " 23  NNS                7520 non-null   float64\n",
      " 24  VBP                7520 non-null   float64\n",
      " 25  IN                 7520 non-null   float64\n",
      " 26  MD                 7520 non-null   float64\n",
      " 27  VB                 7520 non-null   float64\n",
      " 28  JJ                 7520 non-null   float64\n",
      " 29  PRP                7520 non-null   float64\n",
      " 30  JJS                7520 non-null   float64\n",
      " 31  VBN                7520 non-null   float64\n",
      " 32  VBD                7520 non-null   float64\n",
      " 33  TO                 7520 non-null   float64\n",
      " 34  VBG                7520 non-null   float64\n",
      " 35  CC                 7520 non-null   float64\n",
      " 36  RB                 7520 non-null   float64\n",
      " 37  EX                 7520 non-null   float64\n",
      " 38  VBZ                7520 non-null   float64\n",
      " 39  CD                 7520 non-null   float64\n",
      " 40  WP                 7520 non-null   float64\n",
      " 41  RP                 7520 non-null   float64\n",
      " 42  JJR                7520 non-null   float64\n",
      " 43  WRB                7520 non-null   float64\n",
      " 44  FW                 7520 non-null   float64\n",
      " 45  WDT                7520 non-null   float64\n",
      " 46  NNP                7520 non-null   float64\n",
      " 47  RBR                7520 non-null   float64\n",
      " 48  RBS                7520 non-null   float64\n",
      " 49  PDT                7520 non-null   float64\n",
      " 50  SYM                7520 non-null   float64\n",
      " 51  UH                 7520 non-null   float64\n",
      " 52  WP$                7520 non-null   float64\n",
      "dtypes: float64(40), int64(10), object(3)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence_count',\n",
       " 'word_count',\n",
       " 'stop_word_count',\n",
       " 'stop_word_share',\n",
       " 'url_count',\n",
       " 'mean_word_length',\n",
       " 'char_count',\n",
       " 'punctuation_count',\n",
       " 'hashtag_count',\n",
       " 'mention_count',\n",
       " 'polarity_raw',\n",
       " 'subjectivity_raw',\n",
       " 'unique_word_count',\n",
       " 'unique_word_share',\n",
       " 'polarity',\n",
       " 'subjectivity',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'IN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'JJS',\n",
       " 'VBN',\n",
       " 'VBD',\n",
       " 'TO',\n",
       " 'VBG',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'EX',\n",
       " 'VBZ',\n",
       " 'CD',\n",
       " 'WP',\n",
       " 'RP',\n",
       " 'JJR',\n",
       " 'WRB',\n",
       " 'FW',\n",
       " 'WDT',\n",
       " 'NNP',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'PDT',\n",
       " 'SYM',\n",
       " 'UH',\n",
       " 'WP$']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_analysis = list(train_df_new)[4:]\n",
    "feature_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write csv file with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_NEW = os.path.join(DATA_PATH, 'train_new_features.csv')\n",
    "df_train = train_df_new\n",
    "df_train.to_csv(TRAIN_NEW, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
